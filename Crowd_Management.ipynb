{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cd0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kiit\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d5cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.10)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f051e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the file locally\n",
    "with open(\"haarcascade_frontalface_default.xml\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"Download complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b69ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"haarcascade_frontalface_default.xml\"))  # Should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90a5b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cascade classifier loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(\"Failed to load cascade classifier!\")\n",
    "else:\n",
    "    print(\"Cascade classifier loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda1d4c",
   "metadata": {},
   "source": [
    "# Opening the Web Cam and detecting the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ec2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the live photo frontal face\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open webcam (0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale (Haar cascades work better in grayscale)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43296fec",
   "metadata": {},
   "source": [
    "# Detecting Face and Back of the Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539524e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frontal and backward version\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifiers for face and upper body detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "upperbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly, ret is True\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale (Haar Cascade works on grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5,minSize=(30, 30) )\n",
    "\n",
    "    # If no faces are detected, try detecting upper bodies\n",
    "    if len(faces) == 0:\n",
    "        upper_bodies = upperbody_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        for (x, y, w, h) in upper_bodies:\n",
    "            # Draw a rectangle around the detected upper body (back of the head approximation)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Back of Head Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            # Save the image when back of the head is detected\n",
    "            cv2.imwrite('back_of_head.png', frame)\n",
    "    else:\n",
    "        # Draw a rectangle around each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Blue rectangle for face\n",
    "            cv2.putText(frame, 'Face Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            # Save the image when a face is detected\n",
    "            cv2.imwrite('face_detected.png', frame)\n",
    "\n",
    "    # Display the frame with rectangles\n",
    "    cv2.imshow('Face and Head Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cae620",
   "metadata": {},
   "source": [
    "# Setting the threshold and check for overcrowding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce96241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting threshold so that it will display the crowd\n",
    "import cv2\n",
    "# Load the pre-trained Haar Cascade classifiers for face and upper body detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "upperbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Set the threshold for overcrowding\n",
    "crowd_threshold = 5  # You can adjust this limit as needed\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly, ret is True\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale (Haar Cascade works on grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    num_individuals = len(faces)  # Start counting the number of detected individuals with faces\n",
    "\n",
    "    # If no faces are detected, try detecting upper bodies\n",
    "    if num_individuals == 0:\n",
    "        upper_bodies = upperbody_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        num_individuals += len(upper_bodies)  # Add the detected upper bodies to the count\n",
    "        for (x, y, w, h) in upper_bodies:\n",
    "            # Draw a rectangle around the detected upper body (back of the head approximation)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Back of Head Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            # Save the image when back of the head is detected\n",
    "            cv2.imwrite('back_of_head.png', frame)\n",
    "    else:\n",
    "        # Draw a rectangle around each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Blue rectangle for face\n",
    "            cv2.putText(frame, 'Face Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            # Save the image when a face is detected\n",
    "            cv2.imwrite('face_detected.png', frame)\n",
    "\n",
    "    # Check if the count exceeds the threshold and display overcrowding warning\n",
    "    if num_individuals > crowd_threshold:\n",
    "        cv2.putText(frame, 'Warning: Overcrowded!', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, f'Occupancy: {num_individuals}/{crowd_threshold}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with rectangles\n",
    "    cv2.imshow('Face and Head Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4fd3b1",
   "metadata": {},
   "source": [
    "# Generating Voice Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voice assistant feature\n",
    "import cv2\n",
    "import pyttsx3\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifiers for face and upper body detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "upperbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set the threshold for overcrowding\n",
    "crowd_threshold = 5  # You can adjust this limit as needed\n",
    "last_announcement = \"\"  # Track the last announcement to avoid repetitive announcements\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly, ret is True\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale (Haar Cascade works on grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    num_individuals = len(faces)  # Start counting the number of detected individuals with faces\n",
    "\n",
    "    # If no faces are detected, try detecting upper bodies\n",
    "    if num_individuals == 0:\n",
    "        upper_bodies = upperbody_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        num_individuals += len(upper_bodies)  # Add the detected upper bodies to the count\n",
    "        for (x, y, w, h) in upper_bodies:\n",
    "            # Draw a rectangle around the detected upper body (back of the head approximation)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Back of Head Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            # Save the image when back of the head is detected\n",
    "            cv2.imwrite('back_of_head.png', frame)\n",
    "    else:\n",
    "        # Draw a rectangle around each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Blue rectangle for face\n",
    "            cv2.putText(frame, 'Face Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            # Save the image when a face is detected\n",
    "            cv2.imwrite('face_detected.png', frame)\n",
    "\n",
    "    # Check if the count exceeds the threshold and display overcrowding warning\n",
    "    if num_individuals > crowd_threshold:\n",
    "        cv2.putText(frame, 'Warning: Overcrowded!', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        announcement = f\"Warning: Overcrowded! {num_individuals} individuals detected.\"\n",
    "    else:\n",
    "        cv2.putText(frame, f'Occupancy: {num_individuals}/{crowd_threshold}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        announcement = f\"{num_individuals} individuals detected. The occupancy is within the safe limit.\"\n",
    "\n",
    "    # Make the voice announcement only if it's different from the last announcement\n",
    "    if announcement != last_announcement:\n",
    "        engine.say(announcement)\n",
    "        engine.runAndWait()\n",
    "        last_announcement = announcement  # Update last announcement to avoid repetition\n",
    "\n",
    "    # Display the frame with rectangles\n",
    "    cv2.imshow('Face and Head Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f283b47",
   "metadata": {},
   "source": [
    "# Crowd detection using CSRNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision numpy scipy opencv-python matplotlib h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843058f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This prints your Jupyter Notebook's working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"shanghaitech.zip\"  # Change this to your actual ZIP file name if different\n",
    "extract_path = \"shanghaitech\"  # Folder to extract\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"shanghaitech\"  # Change if you extracted it elsewhere\n",
    "\n",
    "# List all files in the dataset directory\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb124e",
   "metadata": {},
   "source": [
    "# Defining the CSRNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Define Paths\n",
    "DATASET_PATH = \"shanghaitech\"  # Root dataset folder\n",
    "\n",
    "# Step 2: Define the CSRNet Model\n",
    "class CSRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CSRNet, self).__init__()\n",
    "        # Use the first 23 layers of VGG16 as the frontend\n",
    "        self.frontend = models.vgg16(pretrained=True).features[:23]\n",
    "        # Define the backend with additional convolutional layers\n",
    "        self.backend = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11daa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Preprocess the Image and Generate Density Map\n",
    "def load_image(img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def generate_density_map(image_shape, points):\n",
    "    density_map = np.zeros(image_shape[:2], dtype=np.float32)\n",
    "    for point in points:\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        if 0 <= y < density_map.shape[0] and 0 <= x < density_map.shape[1]:\n",
    "            density_map[y, x] = 1\n",
    "    return gaussian_filter(density_map, sigma=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load the Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CSRNet().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Training Function\n",
    "def train_model(model, dataloader, num_epochs=10, learning_rate=1e-4):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, density_maps in dataloader:\n",
    "            images, density_maps = images.to(device), density_maps.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, density_maps)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b676830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Implement Crowd Estimation with Voice Alert\n",
    "def estimate_crowd(img_path, model):\n",
    "    model.eval()\n",
    "    image = load_image(img_path).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image).cpu().numpy()[0, 0]\n",
    "    estimated_count = np.sum(output)\n",
    "    print(f\"Estimated crowd count: {int(estimated_count)}\")\n",
    "    if estimated_count > 50:\n",
    "        os.system(\"say 'High crowd density detected. Take necessary precautions.'\")\n",
    "    plt.imshow(output, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSRNet Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CSRNet().to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to estimate crowd from a webcam frame\n",
    "def estimate_crowd_from_frame(frame):\n",
    "    # Convert OpenCV frame to PIL Image\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Transform image for model input\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(image).cpu().numpy()[0, 0]\n",
    "    \n",
    "    # Estimate crowd count\n",
    "    estimated_count = np.sum(output)\n",
    "    \n",
    "    # Show density map (optional)\n",
    "    plt.imshow(output, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print estimated count\n",
    "    print(f\"Estimated Crowd Count: {int(estimated_count)}\")\n",
    "    \n",
    "    # Voice alert for high crowd density\n",
    "    if estimated_count > 50:\n",
    "        os.system(\"say 'High crowd density detected. Take necessary precautions.'\")\n",
    "\n",
    "    return int(estimated_count)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Estimate crowd density\n",
    "    count = estimate_crowd_from_frame(frame)\n",
    "    \n",
    "    # Display count on video frame\n",
    "    cv2.putText(frame, f\"Crowd Count: {count}\", (50, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Show the video frame\n",
    "    cv2.imshow(\"Live Crowd Detection\", frame)\n",
    "    \n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db420a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
